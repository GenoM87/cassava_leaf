{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit0a42446d5daf47b1a11277f27a4482e4",
   "display_name": "Python 3.6.9 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "#!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade albumentations\n",
    "!pip install neptune-client\n",
    "!pip install pytorch-lightning\n",
    "!pip install pytorch_ranger\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
    "!pip install timm\n",
    "!pip install yacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /root/.kaggle/\n",
    "!cp -avr /content/drive/MyDrive/kaggle.json /root/.kaggle/\n",
    "\n",
    "!kaggle competitions download -c cassava-leaf-disease-classification\n",
    "!git clone https://github.com/GenoM87/cassava_leaf.git\n",
    "!mkdir cassava_leaf/data\n",
    "!mkdir cassava_leaf/experiments\n",
    "!unzip cassava-leaf-disease-classification.zip -d cassava_leaf/data\n",
    "\n",
    "!python cassava_leaf/src/create_folds.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys, os, time, logging, datetime, random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from config import _C as cfg\n",
    "from models.create_model import CustomNet\n",
    "\n",
    "from data_builder import build_valid_loader, build_train_loader\n",
    "from models.optimizer import make_optimizer\n",
    "from models.scheduler import make_scheduler\n",
    "\n",
    "#TODO: provare ad usare questo\n",
    "from models.loss import BiTemperedLogisticLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo lla directory per l'esperimento\n",
    "path_exp = os.path.join(\n",
    "    cfg.PROJECT_DIR, 'experiments', cfg.MODEL.NAME, str(datetime.date.today())\n",
    ")\n",
    "\n",
    "Path(path_exp).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=2004):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "set_seed(cfg.RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hmapModel(pl.LightningModule):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.model = CustomNet(\n",
    "        cfg\n",
    "    )\n",
    "    self.train_accuracy = pl.metrics.Accuracy()\n",
    "    self.valid_accuracy = pl.metrics.Accuracy()\n",
    "    self.loss_fn = BiTemperedLogisticLoss(\n",
    "        t1=cfg.SOLVER.BIT_T1,\n",
    "        t2=cfg.SOLVER.BIT_T2,\n",
    "        smoothing=cfg.SOLVER.SMOOTHING_LOSS \n",
    "    )\n",
    "        \n",
    "  def forward(self, x):\n",
    "      return self.model(x)\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "      x, y = batch\n",
    "      y_hat = self.model(x)\n",
    "      loss = self.loss_fn(y_hat, y)\n",
    "      #loss = symmetric_lovasz(y_hat, y)\n",
    "      train_dice = dice_fn(y_hat, y)\n",
    "      self.log('train_loss', loss)\n",
    "      self.log(\n",
    "          'train_dice', \n",
    "          train_dice.item(), \n",
    "          on_step=False, \n",
    "          on_epoch=True, \n",
    "          logger=True\n",
    "      )\n",
    "      return {'loss': loss, 'train_dice': train_dice.item()}\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "      optimizer = torch.optim.Adam(self.parameters(), lr=CONFIG['lr'])\n",
    "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=4)\n",
    "      return {\n",
    "       'optimizer': optimizer,\n",
    "       'lr_scheduler': scheduler,\n",
    "       'monitor': 'val_loss'\n",
    "      }\n",
    "\n",
    "  def train_dataloader(self):\n",
    "      dataset = HuBMAPDataset(\n",
    "          train_ids,\n",
    "          tfms=get_train_aug(CONFIG['size'])\n",
    "      )\n",
    "      loader = DataLoader(\n",
    "          dataset,\n",
    "          batch_size=CONFIG['train_batch_size'], \n",
    "          shuffle=True,\n",
    "          num_workers=CONFIG['num_workers']\n",
    "      )\n",
    "      return loader\n",
    "  \n",
    "  def val_dataloader(self):\n",
    "      dataset = HuBMAPDataset(\n",
    "          val_ids,\n",
    "          tfms=get_valid_aug(CONFIG['size'])\n",
    "      )\n",
    "      loader = DataLoader(\n",
    "          dataset,\n",
    "          batch_size=CONFIG['val_batch_size'], \n",
    "          shuffle=False,\n",
    "          num_workers=CONFIG['num_workers']\n",
    "      )\n",
    "      return loader\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "      x, y = batch\n",
    "      y_hat = self.model(x).squeeze(1)\n",
    "      val_loss = loss_fn(y_hat, y.float())\n",
    "      val_dice = dice_fn(y_hat, y)\n",
    "      self.log('val_loss', val_loss)\n",
    "      self.log(\n",
    "          'valid_dice', \n",
    "          val_dice.item(), \n",
    "          on_step=False, \n",
    "          on_epoch=True, \n",
    "          logger=True\n",
    "      )\n",
    "      return {'val_loss': val_loss, 'valid_dice': val_dice.item()}"
   ]
  }
 ]
}