{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "kaggleenv",
   "display_name": "kaggleEnv",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from data_builder.builder import build_valid_loader\n",
    "from models.create_model import CustomNet\n",
    "from config import _C as cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = build_test_loader(cfg)\n",
    "model = CustomNet(cfg)\n",
    "\n",
    "checkpoint = torch.load(cfg.CHECKPOINT_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Valid: 100%|██████████| 457/457 [02:00<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.to(cfg.DEVICE)\n",
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "target = []\n",
    "confidence = []\n",
    "\n",
    "test_loader = tqdm(test_loader, total=len(test_loader), desc='Valid')\n",
    "for cnt, (imgs, targets, idxs) in enumerate(test_loader):\n",
    "\n",
    "    imgs = imgs.to(cfg.DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs)\n",
    "        \n",
    "        softmax = torch.nn.Softmax(dim=1)(logits).detach().cpu().numpy()\n",
    "        prediction_class = np.argmax(a=softmax, axis=1)\n",
    "        conf = np.max(a=softmax, axis=1)\n",
    "\n",
    "        preds.append(prediction_class)\n",
    "        confidence.append(conf)\n",
    "        target.append(targets.detach().cpu().numpy())\n",
    "\n",
    "target = np.concatenate(target, axis=0)\n",
    "confidence = np.concatenate(confidence, axis=0)\n",
    "preds = np.concatenate(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 258   16   16    9   55]\n [  26  664   28   20   46]\n [   4   17  767   46   23]\n [   5   14   80 4443   34]\n [  40   43   60   47  538]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(target, preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "for class 0: accuracy: 72.88135593220339\nfor class 1: accuracy: 84.6938775510204\nfor class 2: accuracy: 89.49824970828472\nfor class 3: accuracy: 97.09353146853147\nfor class 4: accuracy: 73.9010989010989\n"
     ]
    }
   ],
   "source": [
    "for i, val in enumerate(cm):\n",
    "    print(\"for class {}: accuracy: {}\".format(i, val[i]/sum(val)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "91.38238114810248"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "np.sum(target==preds)/len(target)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.9758552 , 0.98574173, 0.9795562 , ..., 0.98359585, 0.9695898 ,\n",
       "       0.8129119 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "len(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(confidence)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.335761  , 0.3588644 , 0.4413463 , 0.44890353, 0.45404968],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "confidence[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}